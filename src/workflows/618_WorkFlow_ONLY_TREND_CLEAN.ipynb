{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow 618 - ONLY TREND Features\n",
    "\n",
    "Feature Engineering con SOLO features de tendencia (trend_3, trend_6).\n",
    "\n",
    "L√≥gica id√©ntica a z610 baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 1: Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 2: Descargar dataset\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Crear directorio para datasets\n",
    "os.makedirs('/content/drive/MyDrive/labo2025v/datasets', exist_ok=True)\n",
    "\n",
    "# URL del dataset\n",
    "dataset_url = 'https://storage.googleapis.com/open-courses/austral2025-af91/gerencial_competencia_2025.csv.gz'\n",
    "dataset_path = '/content/drive/MyDrive/labo2025v/datasets/gerencial_competencia_2025.csv.gz'\n",
    "\n",
    "# Descargar solo si no existe\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f'Descargando dataset desde {dataset_url}...')\n",
    "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "    print(f'‚úì Dataset descargado: {dataset_path}')\n",
    "else:\n",
    "    print(f'‚úì Dataset ya existe: {dataset_path}')\n",
    "\n",
    "# Verificar tama√±o\n",
    "size_mb = os.path.getsize(dataset_path) / (1024**2)\n",
    "print(f'  Tama√±o: {size_mb:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /content/workflow_618.R\n",
    "\n",
    "# ============================================================================\n",
    "# WORKFLOW 618 ONLY TREND - Implementaci√≥n completa en Google Colab\n",
    "# ============================================================================\n",
    "\n",
    "format(Sys.time(), \"%a %b %d %X %Y\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN INICIAL\n",
    "# ============================================================================\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "cat(\" WORKFLOW 618 ONLY TREND\\n\")\n",
    "cat(\"========================================\\n\\n\")\n",
    "\n",
    "# Directorios\n",
    "BASE_DIR <- \"/content/drive/MyDrive/labo2025v\"\n",
    "DATASETS_DIR <- file.path(BASE_DIR, \"datasets\")\n",
    "EXP_DIR <- file.path(BASE_DIR, \"exp\", \"exp_only_trend_colab\")\n",
    "\n",
    "dir.create(EXP_DIR, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "# Configuraci√≥n de semillas\n",
    "SEMILLAS <- c(153929, 838969, 922081, 795581, 194609)\n",
    "\n",
    "cat(\"Configuraci√≥n:\\n\")\n",
    "cat(paste(\"  Base dir:\", BASE_DIR, \"\\n\"))\n",
    "cat(paste(\"  Datasets:\", DATASETS_DIR, \"\\n\"))\n",
    "cat(paste(\"  Experimentos:\", EXP_DIR, \"\\n\"))\n",
    "cat(paste(\"  Semillas:\", length(SEMILLAS), \"\\n\\n\"))\n",
    "\n",
    "# ============================================================================\n",
    "# CARGAR PAQUETES\n",
    "# ============================================================================\n",
    "\n",
    "cat(\"Cargando paquetes...\\n\")\n",
    "\n",
    "library(data.table)\n",
    "library(lightgbm)\n",
    "library(DiceKriging)\n",
    "library(mlr)\n",
    "library(mlrMBO)\n",
    "library(ParamHelpers)\n",
    "\n",
    "setDTthreads(1)  # Colab tiene CPUs limitadas\n",
    "\n",
    "cat(\"‚úì Paquetes cargados\\n\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICAR DATASET\n",
    "# ============================================================================\n",
    "\n",
    "dataset_file <- file.path(DATASETS_DIR, \"gerencial_competencia_2025.csv.gz\")\n",
    "\n",
    "cat(\"Verificando dataset...\\n\")\n",
    "if (!file.exists(dataset_file)) {\n",
    "  stop(\"ERROR: Dataset no encontrado en \", dataset_file)\n",
    "}\n",
    "\n",
    "file_size <- file.info(dataset_file)$size / (1024^2)\n",
    "cat(paste(\"‚úì Dataset encontrado:\", round(file_size, 2), \"MB\\n\\n\"))\n",
    "\n",
    "# ============================================================================\n",
    "# LOOP DE SEMILLAS\n",
    "# ============================================================================\n",
    "\n",
    "resultados_finales <- list()\n",
    "\n",
    "for (seed_idx in 1:length(SEMILLAS)) {\n",
    "  \n",
    "  semilla <- SEMILLAS[seed_idx]\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  cat(paste(rep(\"=\", 80), collapse=\"\"), \"\\n\")\n",
    "  cat(paste(\"SEMILLA\", seed_idx, \"/\", length(SEMILLAS), \"- Valor:\", semilla, \"\\n\"))\n",
    "  cat(paste(rep(\"=\", 80), collapse=\"\"), \"\\n\\n\")\n",
    "  \n",
    "  inicio_seed <- Sys.time()\n",
    "  \n",
    "  # Crear directorio para esta semilla\n",
    "  exp_folder <- paste0(\"WF618\", seed_idx - 1, \"_seed\", seed_idx, \"_ONLY_TREND\")\n",
    "  seed_dir <- file.path(EXP_DIR, exp_folder)\n",
    "  dir.create(seed_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "  \n",
    "  cat(paste(\"Directorio:\", seed_dir, \"\\n\\n\"))\n",
    "  \n",
    "  # ==========================================================================\n",
    "  # CARGA DE DATASET O CACHE\n",
    "  # ==========================================================================\n",
    "  \n",
    "  dataset_cache_file <- file.path(seed_dir, \"dataset_con_FE_ONLY_TREND.rds\")\n",
    "  \n",
    "  if (file.exists(dataset_cache_file)) {\n",
    "    cat(\"üì¶ Cargando dataset desde cache...\\n\")\n",
    "    inicio_cache <- Sys.time()\n",
    "    dataset <- readRDS(dataset_cache_file)\n",
    "    fin_cache <- Sys.time()\n",
    "    tiempo_cache <- as.numeric(difftime(fin_cache, inicio_cache, units = \"secs\"))\n",
    "    \n",
    "    cat(paste(\"‚úì Cache cargado en\", round(tiempo_cache, 1), \"seg\\n\"))\n",
    "    cat(paste(\"  Dimensiones:\", nrow(dataset), \"filas x\", ncol(dataset), \"cols\\n\\n\"))\n",
    "    \n",
    "  } else {\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CARGAR DATASET ORIGINAL\n",
    "    # ========================================================================\n",
    "    \n",
    "    cat(\"üìÇ Cargando dataset original...\\n\")\n",
    "    inicio_carga <- Sys.time()\n",
    "    dataset <- fread(dataset_file)\n",
    "    fin_carga <- Sys.time()\n",
    "    tiempo_carga <- as.numeric(difftime(fin_carga, inicio_carga, units = \"secs\"))\n",
    "    \n",
    "    cat(paste(\"‚úì Dataset cargado en\", round(tiempo_carga, 1), \"seg\\n\"))\n",
    "    cat(paste(\"  Dimensiones:\", nrow(dataset), \"filas x\", ncol(dataset), \"cols\\n\\n\"))\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CATASTROPHE ANALYSIS\n",
    "    # ========================================================================\n",
    "    \n",
    "    cat(\"üî• Aplicando Catastrophe Analysis...\\n\")\n",
    "    \n",
    "    # Asignar NA a 13 variables en foto_mes 202006\n",
    "    dataset[foto_mes == 202006, internet := NA]\n",
    "    dataset[foto_mes == 202006, mrentabilidad := NA]\n",
    "    dataset[foto_mes == 202006, mrentabilidad_annual := NA]\n",
    "    dataset[foto_mes == 202006, mcomisiones := NA]\n",
    "    dataset[foto_mes == 202006, mactivos_margen := NA]\n",
    "    dataset[foto_mes == 202006, mpasivos_margen := NA]\n",
    "    dataset[foto_mes == 202006, mcuentas_saldo := NA]\n",
    "    dataset[foto_mes == 202006, ctarjeta_visa_transacciones := NA]\n",
    "    dataset[foto_mes == 202006, mtarjeta_visa_consumo := NA]\n",
    "    dataset[foto_mes == 202006, mtarjeta_master_consumo := NA]\n",
    "    dataset[foto_mes == 202006, ccallcenter_transacciones := NA]\n",
    "    dataset[foto_mes == 202006, chomebanking_transacciones := NA]\n",
    "    dataset[foto_mes == 202006, ctarjeta_master_transacciones := NA]\n",
    "    \n",
    "    cat(\"‚úì 13 variables en 202006 ‚Üí NA\\n\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FEATURE ENGINEERING - SOLO TRENDS\n",
    "    # ========================================================================\n",
    "    \n",
    "    cat(\"‚öôÔ∏è  Feature Engineering - SOLO TRENDS...\\n\")\n",
    "    inicio_fe <- Sys.time()\n",
    "    \n",
    "    # Variables base (excluir ID, fecha, clase)\n",
    "    cols_lagueables <- setdiff(\n",
    "      colnames(dataset),\n",
    "      c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "    )\n",
    "    \n",
    "    cat(paste(\"  Variables base:\", length(cols_lagueables), \"\\n\"))\n",
    "    \n",
    "    # Ordenar por cliente y mes\n",
    "    setorder(dataset, numero_de_cliente, foto_mes)\n",
    "    \n",
    "    # GENERAR TRENDS (ventanas 3 y 6)\n",
    "    cat(\"  Generando trends...\\n\")\n",
    "    inicio_trends <- Sys.time()\n",
    "    cols_antes_trends <- ncol(dataset)\n",
    "    \n",
    "    for (ventana in c(3, 6)) {\n",
    "      cat(paste(\"    Ventana\", ventana, \"...\"))\n",
    "      \n",
    "      for (col in cols_lagueables) {\n",
    "        trend_col <- paste0(col, \"_trend_\", ventana)\n",
    "        \n",
    "        dataset[, (trend_col) := {\n",
    "          if (.N >= ventana) {\n",
    "            valores <- tail(get(col), ventana)\n",
    "            if (all(is.na(valores))) {\n",
    "              NA_real_\n",
    "            } else {\n",
    "              x <- 1:ventana\n",
    "              y <- valores\n",
    "              validos <- !is.na(y)\n",
    "              if (sum(validos) >= 2) {\n",
    "                coef(lm(y[validos] ~ x[validos]))[2]\n",
    "              } else {\n",
    "                NA_real_\n",
    "              }\n",
    "            }\n",
    "          } else {\n",
    "            NA_real_\n",
    "          }\n",
    "        }, by = numero_de_cliente]\n",
    "      }\n",
    "      \n",
    "      cat(\" OK\\n\")\n",
    "    }\n",
    "    \n",
    "    fin_trends <- Sys.time()\n",
    "    cols_trends <- ncol(dataset) - cols_antes_trends\n",
    "    tiempo_trends <- as.numeric(difftime(fin_trends, inicio_trends, units = \"mins\"))\n",
    "    \n",
    "    cat(paste(\"  ‚úì Trends generadas:\", cols_trends, \"variables en\",\n",
    "              round(tiempo_trends, 1), \"min\\n\"))\n",
    "    \n",
    "    fin_fe <- Sys.time()\n",
    "    tiempo_fe <- as.numeric(difftime(fin_fe, inicio_fe, units = \"mins\"))\n",
    "    \n",
    "    cat(paste(\"‚úì Feature Engineering completado en\", round(tiempo_fe, 1), \"min\\n\"))\n",
    "    cat(paste(\"  Dataset final:\", nrow(dataset), \"filas x\", ncol(dataset), \"cols\\n\\n\"))\n",
    "    \n",
    "    # Guardar en cache\n",
    "    cat(\"üíæ Guardando cache...\\n\")\n",
    "    inicio_save <- Sys.time()\n",
    "    saveRDS(dataset, dataset_cache_file, compress = \"xz\")\n",
    "    fin_save <- Sys.time()\n",
    "    tiempo_save <- as.numeric(difftime(fin_save, inicio_save, units = \"secs\"))\n",
    "    \n",
    "    file_size_mb <- file.info(dataset_cache_file)$size / (1024^2)\n",
    "    cat(paste(\"‚úì Cache guardado:\", round(file_size_mb, 1), \"MB en\",\n",
    "              round(tiempo_save, 1), \"seg\\n\\n\"))\n",
    "  }\n",
    "  \n",
    "  # ==========================================================================\n",
    "  # TRAINING STRATEGY\n",
    "  # ==========================================================================\n",
    "  \n",
    "  cat(\"üéØ Configurando Training Strategy...\\n\")\n",
    "  \n",
    "  # Clase binaria\n",
    "  dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1, 0)]\n",
    "  \n",
    "  # Periodos\n",
    "  training_months <- c(\n",
    "    202104, 202103, 202102, 202101,\n",
    "    202012, 202011, 202010, 202009, 202008, 202007,\n",
    "    202006, 202005\n",
    "  )\n",
    "  \n",
    "  validate_month <- 202105\n",
    "  \n",
    "  final_train_months <- c(\n",
    "    202105, 202104, 202103, 202102, 202101,\n",
    "    202012, 202011, 202010, 202009, 202008, 202007,\n",
    "    202006, 202005\n",
    "  )\n",
    "  \n",
    "  future_month <- 202107\n",
    "  \n",
    "  cat(paste(\"  Training:\", paste(range(training_months), collapse=\" a \"), \"\\n\"))\n",
    "  cat(paste(\"  Validation:\", validate_month, \"\\n\"))\n",
    "  cat(paste(\"  Final train:\", paste(range(final_train_months), collapse=\" a \"), \"\\n\"))\n",
    "  cat(paste(\"  Future:\", future_month, \"\\n\\n\"))\n",
    "  \n",
    "  # Features (excluir IDs y clases)\n",
    "  campos_buenos <- setdiff(\n",
    "    colnames(dataset),\n",
    "    c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\", \"clase01\")\n",
    "  )\n",
    "  \n",
    "  cat(paste(\"  Features para modelo:\", length(campos_buenos), \"\\n\\n\"))\n",
    "  \n",
    "  # Crear datasets LightGBM\n",
    "  dtrain <- lgb.Dataset(\n",
    "    data = data.matrix(dataset[foto_mes %in% training_months, campos_buenos, with = FALSE]),\n",
    "    label = dataset[foto_mes %in% training_months, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "  \n",
    "  dvalidate <- lgb.Dataset(\n",
    "    data = data.matrix(dataset[foto_mes == validate_month, campos_buenos, with = FALSE]),\n",
    "    label = dataset[foto_mes == validate_month, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "  \n",
    "  cat(paste(\"  Train set:\", nrow(dataset[foto_mes %in% training_months]), \"filas\\n\"))\n",
    "  cat(paste(\"  Validation set:\", nrow(dataset[foto_mes == validate_month]), \"filas\\n\\n\"))\n",
    "  \n",
    "  # ==========================================================================\n",
    "  # BAYESIAN OPTIMIZATION\n",
    "  # ==========================================================================\n",
    "  \n",
    "  cat(\"üîç Bayesian Optimization (10 iteraciones)...\\n\")\n",
    "  inicio_bo <- Sys.time()\n",
    "  \n",
    "  set.seed(semilla)\n",
    "  \n",
    "  # Par√°metros fijos\n",
    "  param_fijos <- list(\n",
    "    objective = \"binary\",\n",
    "    metric = \"auc\",\n",
    "    first_metric_only = TRUE,\n",
    "    boost_from_average = TRUE,\n",
    "    feature_pre_filter = FALSE,\n",
    "    verbosity = -100,\n",
    "    force_row_wise = TRUE,\n",
    "    seed = semilla,\n",
    "    max_bin = 31,\n",
    "    learning_rate = 0.03,\n",
    "    feature_fraction = 0.5,\n",
    "    num_iterations = 2048,\n",
    "    early_stopping_rounds = 200\n",
    "  )\n",
    "  \n",
    "  # Par√°metros a optimizar\n",
    "  configuracion_bo <- makeParamSet(\n",
    "    makeIntegerParam(\"num_leaves\", lower = 2L, upper = 256L),\n",
    "    makeIntegerParam(\"min_data_in_leaf\", lower = 2L, upper = 8192L)\n",
    "  )\n",
    "  \n",
    "  # Funci√≥n objetivo\n",
    "  EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "    param_completo <- modifyList(param_fijos, x)\n",
    "    \n",
    "    modelo_train <- lgb.train(\n",
    "      data = dtrain,\n",
    "      valids = list(valid = dvalidate),\n",
    "      eval = \"auc\",\n",
    "      param = param_completo,\n",
    "      verbose = -100\n",
    "    )\n",
    "    \n",
    "    AUC <- modelo_train$record_evals$valid$auc$eval[[modelo_train$best_iter]]\n",
    "    attr(AUC, \"extras\") <- list(\"num_iterations\" = modelo_train$best_iter)\n",
    "    \n",
    "    rm(modelo_train)\n",
    "    gc(full = TRUE, verbose = FALSE)\n",
    "    \n",
    "    return(AUC)\n",
    "  }\n",
    "  \n",
    "  # Configurar BO\n",
    "  configureMlr(show.learner.output = FALSE)\n",
    "  \n",
    "  obj.fun <- makeSingleObjectiveFunction(\n",
    "    fn = EstimarGanancia_AUC_lightgbm,\n",
    "    minimize = FALSE,\n",
    "    noisy = FALSE,\n",
    "    par.set = configuracion_bo,\n",
    "    has.simple.signature = FALSE\n",
    "  )\n",
    "  \n",
    "  # Control de BO\n",
    "  ctrl <- makeMBOControl()\n",
    "  ctrl <- setMBOControlTermination(ctrl, iters = 10L)\n",
    "  ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "  \n",
    "  surr.km <- makeLearner(\n",
    "    \"regr.km\",\n",
    "    predict.type = \"se\",\n",
    "    covtype = \"matern3_2\",\n",
    "    control = list(trace = FALSE)\n",
    "  )\n",
    "  \n",
    "  # Ejecutar BO\n",
    "  bayesiana_salida <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "  \n",
    "  fin_bo <- Sys.time()\n",
    "  tiempo_bo <- as.numeric(difftime(fin_bo, inicio_bo, units = \"mins\"))\n",
    "  \n",
    "  # Extraer mejores hiperpar√°metros\n",
    "  tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "  setorder(tb_bayesiana, -y, -num_iterations)\n",
    "  \n",
    "  fwrite(tb_bayesiana, file.path(seed_dir, \"BO_log.txt\"), sep = \"\\t\")\n",
    "  \n",
    "  mejores_hiperparametros <- tb_bayesiana[\n",
    "    1,\n",
    "    setdiff(colnames(tb_bayesiana),\n",
    "            c(\"y\", \"dob\", \"eol\", \"error.message\", \"exec.time\", \"ei\", \"error.model\",\n",
    "              \"train.time\", \"prop.type\", \"propose.time\", \"se\", \"mean\", \"iter\")),\n",
    "    with = FALSE\n",
    "  ]\n",
    "  \n",
    "  mejor_auc <- tb_bayesiana[1, y]\n",
    "  \n",
    "  cat(paste(\"‚úì BO completado en\", round(tiempo_bo, 1), \"min\\n\"))\n",
    "  cat(paste(\"  Mejor AUC:\", round(mejor_auc, 6), \"\\n\"))\n",
    "  cat(paste(\"  num_leaves:\", mejores_hiperparametros$num_leaves, \"\\n\"))\n",
    "  cat(paste(\"  min_data_in_leaf:\", mejores_hiperparametros$min_data_in_leaf, \"\\n\"))\n",
    "  cat(paste(\"  num_iterations:\", mejores_hiperparametros$num_iterations, \"\\n\\n\"))\n",
    "  \n",
    "  # ==========================================================================\n",
    "  # ENTRENAMIENTO MODELO FINAL\n",
    "  # ==========================================================================\n",
    "  \n",
    "  cat(\"üöÄ Entrenando modelo final...\\n\")\n",
    "  inicio_train_final <- Sys.time()\n",
    "  \n",
    "  # Dataset final train\n",
    "  dfinal_train <- lgb.Dataset(\n",
    "    data = data.matrix(dataset[foto_mes %in% final_train_months, campos_buenos, with = FALSE]),\n",
    "    label = dataset[foto_mes %in% final_train_months, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "  \n",
    "  cat(paste(\"  Final train set:\", nrow(dataset[foto_mes %in% final_train_months]), \"filas\\n\"))\n",
    "  \n",
    "  # Par√°metros finales\n",
    "  param_fijos_final <- param_fijos\n",
    "  param_fijos_final$num_iterations <- NULL\n",
    "  param_fijos_final$early_stopping_rounds <- NULL\n",
    "  \n",
    "  param_final <- c(param_fijos_final, mejores_hiperparametros)\n",
    "  \n",
    "  set.seed(semilla)\n",
    "  \n",
    "  final_model <- lgb.train(\n",
    "    data = dfinal_train,\n",
    "    param = param_final,\n",
    "    verbose = -100\n",
    "  )\n",
    "  \n",
    "  fin_train_final <- Sys.time()\n",
    "  tiempo_train_final <- as.numeric(difftime(fin_train_final, inicio_train_final, units = \"mins\"))\n",
    "  \n",
    "  cat(paste(\"‚úì Modelo final entrenado en\", round(tiempo_train_final, 1), \"min\\n\\n\"))\n",
    "  \n",
    "  # Guardar modelo\n",
    "  lgb.save(final_model, file.path(seed_dir, \"modelo.txt\"))\n",
    "  \n",
    "  # Importancia de variables\n",
    "  tb_importancia <- as.data.table(lgb.importance(final_model))\n",
    "  fwrite(tb_importancia, file.path(seed_dir, \"impo.txt\"), sep = \"\\t\")\n",
    "  \n",
    "  # ==========================================================================\n",
    "  # SCORING\n",
    "  # ==========================================================================\n",
    "  \n",
    "  cat(\"üìä Generando predicciones...\\n\")\n",
    "  \n",
    "  dfuture <- dataset[foto_mes == future_month]\n",
    "  \n",
    "  cat(paste(\"  Future set:\", nrow(dfuture), \"filas\\n\"))\n",
    "  \n",
    "  # Predicciones\n",
    "  prediccion <- predict(\n",
    "    final_model,\n",
    "    data.matrix(dfuture[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "  \n",
    "  # Tabla de predicciones\n",
    "  tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "  tb_prediccion[, prob := prediccion]\n",
    "  \n",
    "  fwrite(tb_prediccion, file.path(seed_dir, \"prediccion.txt\"), sep = \"\\t\")\n",
    "  \n",
    "  # Calcular ganancia\n",
    "  tb_prediccion[, clase_ternaria := dfuture$clase_ternaria]\n",
    "  \n",
    "  # Ganancias (z610: 117000 para BAJA+2, -3000 para resto)\n",
    "  tb_prediccion[, ganancia := -3000.0]\n",
    "  tb_prediccion[clase_ternaria == \"BAJA+2\", ganancia := 117000.0]\n",
    "  \n",
    "  # Ordenar y acumular\n",
    "  setorder(tb_prediccion, -prob)\n",
    "  tb_prediccion[, gan_acum := cumsum(ganancia)]\n",
    "  \n",
    "  # Media m√≥vil de ancho 400\n",
    "  tb_prediccion[,\n",
    "                gan_suavizada := frollmean(\n",
    "                  x = gan_acum,\n",
    "                  n = 400,\n",
    "                  align = \"center\",\n",
    "                  na.rm = TRUE,\n",
    "                  hasNA = TRUE\n",
    "                )]\n",
    "  \n",
    "  # Ganancia m√°xima suavizada\n",
    "  ganancia_suavizada_max <- max(tb_prediccion$gan_suavizada, na.rm = TRUE)\n",
    "  envios_optimos <- which.max(tb_prediccion$gan_suavizada)\n",
    "  \n",
    "  cat(paste(\"  Ganancia m√°xima suavizada:\", formatC(ganancia_suavizada_max, format=\"f\", big.mark=\",\", digits=0), \"\\n\"))\n",
    "  cat(paste(\"  Env√≠os √≥ptimos:\", envios_optimos, \"\\n\"))\n",
    "  \n",
    "  # Guardar ganancias\n",
    "  fwrite(tb_prediccion, file.path(seed_dir, \"ganancias.txt\"), sep = \"\\t\")\n",
    "  \n",
    "  # Crear submission\n",
    "  tb_prediccion[, envios := .I]\n",
    "  submission <- tb_prediccion[envios <= envios_optimos, .(numero_de_cliente)]\n",
    "  fwrite(submission, file.path(seed_dir, paste0(\"submission_\", seed_idx, \".csv\")))\n",
    "  \n",
    "  cat(paste(\"‚úì Submission generado:\", nrow(submission), \"env√≠os\\n\\n\"))\n",
    "  \n",
    "  # ==========================================================================\n",
    "  # FIN SEMILLA\n",
    "  # ==========================================================================\n",
    "  \n",
    "  fin_seed <- Sys.time()\n",
    "  duracion_total <- as.numeric(difftime(fin_seed, inicio_seed, units = \"mins\"))\n",
    "  \n",
    "  cat(paste(rep(\"=\", 80), collapse=\"\"), \"\\n\")\n",
    "  cat(paste(\"‚úÖ SEMILLA\", seed_idx, \"COMPLETADA en\", round(duracion_total, 1), \"min\\n\"))\n",
    "  cat(paste(\"   Ganancia:\", formatC(ganancia_suavizada_max, format=\"f\", big.mark=\",\", digits=0), \"\\n\"))\n",
    "  cat(paste(\"   Env√≠os:\", nrow(submission), \"\\n\"))\n",
    "  cat(paste(rep(\"=\", 80), collapse=\"\"), \"\\n\\n\")\n",
    "  \n",
    "  # Guardar resultado\n",
    "  resultados_finales[[seed_idx]] <- list(\n",
    "    seed_idx = seed_idx,\n",
    "    semilla = semilla,\n",
    "    ganancia = ganancia_suavizada_max,\n",
    "    envios = nrow(submission),\n",
    "    envios_optimos = envios_optimos,\n",
    "    duracion_min = duracion_total,\n",
    "    mejor_auc = mejor_auc\n",
    "  )\n",
    "  \n",
    "  # Liberar memoria\n",
    "  rm(dataset, dtrain, dvalidate, dfinal_train, final_model, dfuture, tb_prediccion, submission)\n",
    "  gc(full = TRUE, verbose = FALSE)\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# RESUMEN FINAL\n",
    "# ============================================================================\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(paste(rep(\"=\", 80), collapse=\"\"), \"\\n\")\n",
    "cat(\"RESUMEN FINAL\\n\")\n",
    "cat(paste(rep(\"=\", 80), collapse=\"\"), \"\\n\\n\")\n",
    "\n",
    "# Crear tabla resumen\n",
    "resumen_df <- do.call(rbind, lapply(resultados_finales, function(x) {\n",
    "  data.frame(\n",
    "    seed_idx = x$seed_idx,\n",
    "    semilla = x$semilla,\n",
    "    ganancia = x$ganancia,\n",
    "    envios = x$envios,\n",
    "    envios_optimos = x$envios_optimos,\n",
    "    duracion_min = round(x$duracion_min, 1),\n",
    "    mejor_auc = round(x$mejor_auc, 6)\n",
    "  )\n",
    "}))\n",
    "\n",
    "# Ordenar por ganancia\n",
    "resumen_df <- resumen_df[order(-resumen_df$ganancia), ]\n",
    "resumen_df$rank <- rank(-resumen_df$ganancia)\n",
    "\n",
    "# Guardar resumen\n",
    "fwrite(resumen_df, file.path(EXP_DIR, \"resumen_only_trend_colab.txt\"), sep = \"\\t\")\n",
    "saveRDS(resultados_finales, file.path(EXP_DIR, \"resultados_only_trend_colab.rds\"))\n",
    "\n",
    "cat(\"Resultados por semilla:\\n\\n\")\n",
    "print(resumen_df)\n",
    "\n",
    "# Mejor semilla\n",
    "mejor <- resumen_df[which.max(resumen_df$ganancia), ]\n",
    "cat(\"\\nüèÜ MEJOR SEMILLA:\\n\")\n",
    "cat(paste(\"  Semilla:\", mejor$semilla, \"\\n\"))\n",
    "cat(paste(\"  Ganancia:\", formatC(mejor$ganancia, format=\"f\", big.mark=\",\", digits=0), \"\\n\"))\n",
    "cat(paste(\"  Env√≠os:\", mejor$envios, \"\\n\"))\n",
    "cat(paste(\"  Duraci√≥n:\", mejor$duracion_min, \"min\\n\"))\n",
    "\n",
    "cat(\"\\n‚ú® WORKFLOW COMPLETADO ‚ú®\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 3: Ejecutar workflow\n",
    "!Rscript /content/workflow_618.R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

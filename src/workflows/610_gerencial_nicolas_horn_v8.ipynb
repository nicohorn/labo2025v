{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 610 WorkFlow Gerencial - Nicolas Horn (v8)\n\n**Hiperparametros optimizados (6 params con BO 250 iters):**\n- num_leaves = 289\n- min_data_in_leaf = 279\n- max_depth = 10\n- lambda_l1 = 0.529 (regularizacion L1)\n- lambda_l2 = 3.062 (regularizacion L2)\n- min_gain_to_split = 0.070\n- num_iterations = 463\n\n**Parametros fijos mejorados:**\n- feature_fraction = 0.8 (vs 0.5)\n- bagging_fraction = 0.8\n- bagging_freq = 1\n\n**Exclusion de variables leaky:**\n- numero_de_cliente (excluido)\n- foto_mes (excluido)\n\n**Feature Engineering:**\n- Catastrophe Analysis (13 vars -> NA)\n- Data Drifting por IPC\n- lags (1,2,3) + deltas (1,2,3) + trends (3,6)\n\n**Validacion:** 202107 (ganancia local)\n**Cortes Kaggle:** 850, 950, 1050, 1150\n**5 semillas:** 153929, 838969, 922081, 795581, 194609"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seteo Google Colab (Python3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -sf \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json ~/.kaggle 2>/dev/null || true\n",
    "chmod 600 ~/.kaggle/kaggle.json 2>/dev/null || true\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "webfiles=\"https://storage.googleapis.com/open-courses/austral2025-af91/\"\n",
    "destino_local=\"/content/datasets\"\n",
    "destino_bucket=\"/content/buckets/b1/datasets\"\n",
    "archivo=\"gerencial_competencia_2025.csv.gz\"\n",
    "\n",
    "if ! test -f $destino_bucket/$archivo; then\n",
    "  wget $webfiles/$archivo -O $destino_bucket/$archivo\n",
    "fi\n",
    "\n",
    "if ! test -f $destino_local/$archivo; then\n",
    "  cp $destino_bucket/$archivo $destino_local/$archivo\n",
    "fi\n",
    "\n",
    "ls -lh $destino_local/$archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion R\n",
    "\n",
    "**Cambiar Runtime a R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls(all.names=TRUE))\n",
    "gc(full=TRUE, verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "if(!require(\"R.utils\")) install.packages(\"R.utils\")\n",
    "require(\"R.utils\")\n",
    "if(!require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "PARAM_GLOBAL <- list()\nPARAM_GLOBAL$experimento_base <- 6180\nPARAM_GLOBAL$dataset <- \"gerencial_competencia_2025.csv.gz\"\n\nPARAM_GLOBAL$semillas <- c(153929, 838969, 922081, 795581, 194609)\n\n# Cortes para Kaggle (espaciados)\nPARAM_GLOBAL$kaggle_cortes <- c(850, 950, 1050, 1150)\n\n# Variables a excluir (evitan data leakage)\nPARAM_GLOBAL$excluir_campos <- c(\"numero_de_cliente\", \"foto_mes\")\n\nresultados_totales <- list()\n\ncat(\"Configuracion v8:\\n\")\ncat(\"  Excluir:\", paste(PARAM_GLOBAL$excluir_campos, collapse=\", \"), \"\\n\")\ncat(\"  Cortes:\", paste(PARAM_GLOBAL$kaggle_cortes, collapse=\", \"), \"\\n\")\ncat(\"  Semillas:\", length(PARAM_GLOBAL$semillas), \"\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfoto_mes <- c(\n",
    "  202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104, 202105, 202106, 202107\n",
    ")\n",
    "\n",
    "vIPC <- c(\n",
    "  1.2118694724, 1.1881073259,\n",
    "  1.1693969743, 1.1375456949, 1.1065619600,\n",
    "  1.0681100000, 1.0370000000, 1.0000000000,\n",
    "  0.9680542110, 0.9344152616, 0.8882274350,\n",
    "  0.8532444140, 0.8251880213, 0.8003763543,\n",
    "  0.7763107219\n",
    ")\n",
    "\n",
    "tb_indices <- data.table(foto_mes = vfoto_mes, IPC = vIPC)\n",
    "print(tb_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion Tendencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_slope_fast <- function(y) {\n",
    "  n <- length(y)\n",
    "  valid <- !is.na(y)\n",
    "  n_valid <- sum(valid)\n",
    "  if (n_valid < 2) return(NA_real_)\n",
    "  \n",
    "  x <- 1:n\n",
    "  x_valid <- x[valid]\n",
    "  y_valid <- y[valid]\n",
    "  \n",
    "  sum_x <- sum(x_valid)\n",
    "  sum_y <- sum(y_valid)\n",
    "  sum_xy <- sum(x_valid * y_valid)\n",
    "  sum_x2 <- sum(x_valid^2)\n",
    "  \n",
    "  denom <- n_valid * sum_x2 - sum_x^2\n",
    "  if (denom == 0) return(NA_real_)\n",
    "  \n",
    "  (n_valid * sum_xy - sum_x * sum_y) / denom\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Hiperparametros Optimizados (BO 250 iters)\n\nEstos hiperparametros fueron encontrados localmente con Bayesian Optimization extensa (250 iteraciones)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Hiperparametros optimizados con BO (250 iteraciones)\n\nMEJORES_HIPERPARAMETROS <- list(\n  # Optimizados por BO (6 parametros)\n  num_leaves = 289,\n  min_data_in_leaf = 279,\n  max_depth = 10,\n  lambda_l1 = 0.5291058,\n  lambda_l2 = 3.061922,\n  min_gain_to_split = 0.07016705,\n  num_iterations = 463\n)\n\ncat(\"Hiperparametros optimizados:\\n\")\nfor (param in names(MEJORES_HIPERPARAMETROS)) {\n  cat(\"  \", param, \"=\", MEJORES_HIPERPARAMETROS[[param]], \"\\n\")\n}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Principal - 5 Semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for (seed_idx in 1:length(PARAM_GLOBAL$semillas)) {\n\n  cat(\"\\n\\n========================================\\n\")\n  cat(\"SEMILLA\", seed_idx, \"de\", length(PARAM_GLOBAL$semillas), \"\\n\")\n  cat(\"Semilla:\", PARAM_GLOBAL$semillas[seed_idx], \"\\n\")\n  cat(\"========================================\\n\\n\")\n\n  inicio_seed <- Sys.time()\n\n  PARAM <- list()\n  PARAM$semilla_primigenia <- PARAM_GLOBAL$semillas[seed_idx]\n  PARAM$experimento <- PARAM_GLOBAL$experimento_base + seed_idx - 1\n  PARAM$dataset <- PARAM_GLOBAL$dataset\n\n  # Carpeta del Experimento\n  if (!dir.exists(\"/content/buckets/b1/exp\")) {\n    dir.create(\"/content/buckets/b1/exp\", showWarnings = FALSE, recursive = TRUE)\n  }\n  \n  setwd(\"/content/buckets/b1/exp\")\n  experimento_folder <- paste0(\"WF\", PARAM$experimento, \"_seed\", seed_idx, \"_v8\")\n  dir.create(experimento_folder, showWarnings=FALSE)\n  setwd(paste0(\"/content/buckets/b1/exp/\", experimento_folder))\n  dir.create(\"kaggle\", showWarnings=FALSE)\n  \n  cat(\"Carpeta:\", experimento_folder, \"\\n\\n\")\n\n  # Carga del dataset\n  cat(\"Cargando dataset...\\n\")\n  dataset <- fread(paste0(\"/content/datasets/\", PARAM$dataset))\n  cat(\"Dataset:\", nrow(dataset), \"x\", ncol(dataset), \"\\n\\n\")\n\n  # Catastrophe Analysis\n  cat(\"Catastrophe Analysis (13 variables -> NA)...\\n\")\n  dataset[foto_mes==202006, internet:=NA]\n  dataset[foto_mes==202006, mrentabilidad:=NA]\n  dataset[foto_mes==202006, mrentabilidad_annual:=NA]\n  dataset[foto_mes==202006, mcomisiones:=NA]\n  dataset[foto_mes==202006, mactivos_margen:=NA]\n  dataset[foto_mes==202006, mpasivos_margen:=NA]\n  dataset[foto_mes==202006, mcuentas_saldo:=NA]\n  dataset[foto_mes==202006, ctarjeta_visa_transacciones:=NA]\n  dataset[foto_mes==202006, mtarjeta_visa_consumo:=NA]\n  dataset[foto_mes==202006, mtarjeta_master_consumo:=NA]\n  dataset[foto_mes==202006, ccallcenter_transacciones:=NA]\n  dataset[foto_mes==202006, chomebanking_transacciones:=NA]\n  dataset[foto_mes==202006, ctarjeta_master_transacciones:=NA]\n\n  # Data Drifting - IPC\n  cat(\"Data Drifting (IPC)...\\n\")\n  campos_monetarios <- colnames(dataset)[colnames(dataset) %like% \"^m\"]\n  dataset[tb_indices, on = \"foto_mes\", (campos_monetarios) := .SD * i.IPC, .SDcols = campos_monetarios]\n\n  # FE Intra-mes\n  cat(\"FE Intra-mes...\\n\")\n  dataset[, kmes := foto_mes %% 100]\n  if(\"mpayroll\" %in% colnames(dataset) & \"cliente_edad\" %in% colnames(dataset))\n    dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n\n  # FE Historico (extendido: lags 1,2,3 + deltas 1,2,3 + trends 3,6)\n  cat(\"FE Historico (lags 1,2,3 + deltas 1,2,3 + trends 3,6)...\\n\")\n  inicio_fe <- Sys.time()\n  setorder(dataset, numero_de_cliente, foto_mes)\n\n  cols_lagueables <- setdiff(colnames(dataset), c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\"))\n\n  # Lags 1, 2, 3\n  cat(\"  Lags...\\n\")\n  dataset[, paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"), by = numero_de_cliente, .SDcols = cols_lagueables]\n  dataset[, paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"), by = numero_de_cliente, .SDcols = cols_lagueables]\n  dataset[, paste0(cols_lagueables, \"_lag3\") := shift(.SD, 3, NA, \"lag\"), by = numero_de_cliente, .SDcols = cols_lagueables]\n\n  # Deltas 1, 2, 3\n  cat(\"  Deltas...\\n\")\n  for (vcol in cols_lagueables) {\n    dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n    dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n    dataset[, paste0(vcol, \"_delta3\") := get(vcol) - get(paste0(vcol, \"_lag3\"))]\n  }\n\n  # Trends 3 y 6\n  cat(\"  Trends...\\n\")\n  for (col in cols_lagueables) {\n    dataset[, paste0(col, \"_trend_3\") := frollapply(get(col), 3, calc_slope_fast, align=\"right\"), by = numero_de_cliente]\n  }\n\n  for (col in cols_lagueables) {\n    dataset[, paste0(col, \"_trend_6\") := frollapply(get(col), 6, calc_slope_fast, align=\"right\"), by = numero_de_cliente]\n  }\n\n  cat(\"FE completado en\", round(difftime(Sys.time(), inicio_fe, units=\"mins\"), 1), \"min\\n\")\n  cat(\"Dataset:\", ncol(dataset), \"columnas\\n\\n\")\n\n  # Training Strategy - Validar en 202107\n  cat(\"Training Strategy (validar 202107)...\\n\")\n  PARAM$trainingstrategy <- list()\n  PARAM$trainingstrategy$final_train <- c(202106, 202105, 202104, 202103, 202102, 202101, 202012, 202011, 202010, 202009, 202008, 202007, 202006, 202005)\n  PARAM$trainingstrategy$future <- c(202107)\n\n  dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1, 0)]\n  \n  # EXCLUSION DE VARIABLES LEAKY\n  campos_buenos <- setdiff(colnames(dataset), c(\"clase_ternaria\", \"clase01\", \"azar\"))\n  campos_buenos <- setdiff(campos_buenos, PARAM_GLOBAL$excluir_campos)\n  \n  cat(\"Variables excluidas:\", paste(PARAM_GLOBAL$excluir_campos, collapse=\", \"), \"\\n\")\n\n  set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n  dataset[, azar := runif(nrow(dataset))]\n  dataset[, fold_final_train := foto_mes %in% PARAM$trainingstrategy$final_train]\n\n  cat(\"Features para entrenar:\", length(campos_buenos), \"\\n\\n\")\n\n  # Parametros combinados: fijos mejorados + optimizados\n  cat(\"Configurando modelo con hiperparametros optimizados...\\n\")\n  \n  param_final <- list(\n    # Basicos\n    objective = \"binary\",\n    metric = \"auc\",\n    first_metric_only = TRUE,\n    boost_from_average = TRUE,\n    feature_pre_filter = FALSE,\n    verbosity = -100,\n    force_row_wise = TRUE,\n    seed = PARAM$semilla_primigenia,\n    \n    # Fijos mejorados\n    max_bin = 31,\n    learning_rate = 0.03,\n    feature_fraction = 0.8,\n    bagging_fraction = 0.8,\n    bagging_freq = 1,\n    \n    # Optimizados por BO (250 iters)\n    num_leaves = MEJORES_HIPERPARAMETROS$num_leaves,\n    min_data_in_leaf = MEJORES_HIPERPARAMETROS$min_data_in_leaf,\n    max_depth = MEJORES_HIPERPARAMETROS$max_depth,\n    lambda_l1 = MEJORES_HIPERPARAMETROS$lambda_l1,\n    lambda_l2 = MEJORES_HIPERPARAMETROS$lambda_l2,\n    min_gain_to_split = MEJORES_HIPERPARAMETROS$min_gain_to_split,\n    num_iterations = MEJORES_HIPERPARAMETROS$num_iterations\n  )\n  \n  cat(\"Parametros clave:\\n\")\n  cat(\"  num_leaves =\", param_final$num_leaves, \"\\n\")\n  cat(\"  min_data_in_leaf =\", param_final$min_data_in_leaf, \"\\n\")\n  cat(\"  max_depth =\", param_final$max_depth, \"\\n\")\n  cat(\"  lambda_l1 =\", param_final$lambda_l1, \"\\n\")\n  cat(\"  lambda_l2 =\", param_final$lambda_l2, \"\\n\")\n  cat(\"  feature_fraction =\", param_final$feature_fraction, \"\\n\")\n  cat(\"  bagging_fraction =\", param_final$bagging_fraction, \"\\n\")\n  cat(\"  num_iterations =\", param_final$num_iterations, \"\\n\\n\")\n\n  # Final Training\n  cat(\"Entrenando modelo...\\n\")\n  \n  dfinal_train <- lgb.Dataset(\n    data = data.matrix(dataset[fold_final_train == TRUE, campos_buenos, with = FALSE]),\n    label = dataset[fold_final_train == TRUE, clase01],\n    free_raw_data = TRUE\n  )\n\n  inicio_train <- Sys.time()\n  final_model <- lgb.train(data = dfinal_train, param = param_final, verbose = -100)\n  cat(\"Modelo entrenado en\", round(difftime(Sys.time(), inicio_train, units=\"mins\"), 1), \"min\\n\\n\")\n\n  lgb.save(final_model, \"modelo.txt\")\n  fwrite(as.data.table(lgb.importance(final_model)), file = \"impo.txt\", sep = \"\\t\")\n\n  # Scoring 202107\n  cat(\"Scoring 202107...\\n\")\n  dfuture <- dataset[foto_mes %in% PARAM$trainingstrategy$future]\n  prediccion <- predict(final_model, data.matrix(dfuture[, campos_buenos, with = FALSE]))\n\n  tb_prediccion <- dfuture[, list(numero_de_cliente)]\n  tb_prediccion[, prob := prediccion]\n  fwrite(tb_prediccion, file = \"prediccion.txt\", sep = \"\\t\")\n\n  # Curva de Ganancia (validacion local)\n  tb_prediccion[, clase_ternaria := dfuture$clase_ternaria]\n  tb_prediccion[, ganancia := -3000.0]\n  tb_prediccion[clase_ternaria == \"BAJA+2\", ganancia := 117000.0]\n\n  setorder(tb_prediccion, -prob)\n  tb_prediccion[, gan_acum := cumsum(ganancia)]\n  tb_prediccion[, gan_suavizada := frollmean(gan_acum, 400, align=\"center\", na.rm=TRUE)]\n\n  resultado <- list()\n  resultado$ganancia_suavizada_max <- max(tb_prediccion$gan_suavizada, na.rm=TRUE)\n  resultado$envios <- which.max(tb_prediccion$gan_suavizada)\n  resultado$semilla <- PARAM$semilla_primigenia\n  resultado$seed_idx <- seed_idx\n\n  # Ganancia en los cortes especificos\n  resultado$ganancia_cortes <- list()\n  for (corte in PARAM_GLOBAL$kaggle_cortes) {\n    resultado$ganancia_cortes[[as.character(corte)]] <- tb_prediccion[corte, gan_acum]\n  }\n\n  fwrite(tb_prediccion, file = \"ganancias.txt\", sep = \"\\t\")\n\n  # Grafico\n  tb_prediccion[, envios_num := .I]\n  pdf(\"curva_de_ganancia.pdf\")\n  plot(x = tb_prediccion$envios_num, y = tb_prediccion$gan_acum, type = \"l\", col = \"gray\",\n       xlim = c(0, 6000), ylim = c(0, 8000000),\n       main = paste0(\"Seed \", seed_idx, \" (v8) - Gan=\", as.integer(resultado$ganancia_suavizada_max)),\n       xlab = \"Envios\", ylab = \"Ganancia\", panel.first = grid())\n  abline(v = PARAM_GLOBAL$kaggle_cortes, col = \"red\", lty = 2)\n  dev.off()\n\n  # Generar CSVs para Kaggle (sin enviar)\n  cat(\"Generando CSVs para Kaggle (cortes:\", paste(PARAM_GLOBAL$kaggle_cortes, collapse=\", \"), \")...\\n\")\n  for (envios in PARAM_GLOBAL$kaggle_cortes) {\n    tb_prediccion[, Predicted := 0L]\n    tb_prediccion[1:envios, Predicted := 1L]\n    archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n    fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)], file = archivo_kaggle, sep = \",\")\n    cat(\"  ->\", archivo_kaggle, \"| Ganancia local:\", as.integer(tb_prediccion[envios, gan_acum]), \"\\n\")\n  }\n\n  # Guardar\n  if(!require(\"yaml\")) install.packages(\"yaml\")\n  require(\"yaml\")\n  PARAM$resultado <- resultado\n  PARAM$mejores_hiperparametros <- MEJORES_HIPERPARAMETROS\n  write_yaml(PARAM, file = \"PARAM.yml\")\n\n  resultados_totales[[seed_idx]] <- resultado\n\n  fin_seed <- Sys.time()\n  duracion <- as.numeric(difftime(fin_seed, inicio_seed, units = \"mins\"))\n\n  rm(dataset, dfinal_train, final_model, tb_prediccion, dfuture)\n  gc(full = TRUE, verbose = FALSE)\n\n  cat(\"\\n========================================\\n\")\n  cat(\"Semilla\", seed_idx, \"completada en\", round(duracion, 1), \"min\\n\")\n  cat(\"Ganancia max:\", formatC(resultado$ganancia_suavizada_max, format=\"f\", big.mark=\",\", digits=0), \"\\n\")\n  cat(\"Envios optimos:\", resultado$envios, \"\\n\")\n  cat(\"========================================\\n\")\n}\n\ncat(\"\\n*** TODAS LAS SEMILLAS PROCESADAS ***\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "setwd(\"/content/buckets/b1/exp\")\n\ntb_resumen <- data.table(\n  seed_idx = sapply(resultados_totales, function(x) x$seed_idx),\n  semilla = sapply(resultados_totales, function(x) x$semilla),\n  ganancia = sapply(resultados_totales, function(x) x$ganancia_suavizada_max),\n  envios = sapply(resultados_totales, function(x) x$envios)\n)\n\n# Agregar ganancias por corte\nfor (corte in PARAM_GLOBAL$kaggle_cortes) {\n  col_name <- paste0(\"gan_\", corte)\n  tb_resumen[, (col_name) := sapply(resultados_totales, function(x) x$ganancia_cortes[[as.character(corte)]])]\n}\n\ntb_resumen[, rank := rank(-ganancia)]\n\ncat(\"\\n========================================\\n\")\ncat(\"RESUMEN FINAL - v8\\n\")\ncat(\"========================================\\n\\n\")\nprint(tb_resumen)\n\ncat(\"\\nESTADISTICAS:\\n\")\ncat(\"Ganancia promedio:\", formatC(mean(tb_resumen$ganancia), format=\"f\", big.mark=\",\", digits=0), \"\\n\")\ncat(\"Ganancia maxima:\", formatC(max(tb_resumen$ganancia), format=\"f\", big.mark=\",\", digits=0), \"\\n\")\ncat(\"Ganancia minima:\", formatC(min(tb_resumen$ganancia), format=\"f\", big.mark=\",\", digits=0), \"\\n\")\n\ncat(\"\\nGANANCIA PROMEDIO POR CORTE:\\n\")\nfor (corte in PARAM_GLOBAL$kaggle_cortes) {\n  col_name <- paste0(\"gan_\", corte)\n  cat(\"  Corte\", corte, \":\", formatC(mean(tb_resumen[[col_name]]), format=\"f\", big.mark=\",\", digits=0), \"\\n\")\n}\n\ncat(\"\\nCOMPARACION:\\n\")\ncat(\"  WF6300 original (Kaggle): 4,587,000\\n\")\ncat(\"  v8 promedio (local Jul):\", formatC(mean(tb_resumen$ganancia), format=\"f\", big.mark=\",\", digits=0), \"\\n\")\n\nfwrite(tb_resumen, file = paste0(\"resumen_v8_exp\", PARAM_GLOBAL$experimento_base, \".txt\"), sep = \"\\t\")\nsaveRDS(resultados_totales, file = paste0(\"resultados_v8_exp\", PARAM_GLOBAL$experimento_base, \".rds\"))\n\ncat(\"\\nCSVs para Kaggle generados en cada carpeta WF*/kaggle/\\n\")\ncat(\"Cuando se reseteen los submissions, subir manualmente.\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}